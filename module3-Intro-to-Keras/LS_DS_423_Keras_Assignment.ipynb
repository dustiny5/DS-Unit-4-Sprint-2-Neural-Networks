{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pBQsZEJmubLs"
   },
   "source": [
    "## Use the Keras Library to build a Multi-Layer Perceptron Model on the Boston Housing dataset\n",
    "\n",
    "- The Boston Housing dataset comes with the Keras library so use Keras to import it into your notebook. \n",
    "- Normalize the data (all features should have roughly the same scale)\n",
    "- Import the type of model and layers that you will need from Keras.\n",
    "- Instantiate a model object and use `model.add()` to add layers to your model\n",
    "- Since this is a regression model you will have a single output node in the final layer.\n",
    "- Use activation functions that are appropriate for this task\n",
    "- Compile your model\n",
    "- Fit your model and report its accuracy in terms of Mean Squared Error\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Run this same data through a linear regression model. Which achieves higher accuracy?\n",
    "- Do a little bit of feature engineering and see how that affects your neural network model. (you will need to change your model to accept more inputs)\n",
    "- After feature engineering, which model sees a greater accuracy boost due to the new features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8NLTAR87uYJ-"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data into training and testing\n",
    "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to floats\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "X_train = keras.utils.normalize(X_train, axis=1)\n",
    "X_test = keras.utils.normalize(X_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404, 13), (404,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0717 13:59:59.872238 12168 deprecation.py:506] From C:\\Users\\Dustin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model\n",
    "house = Sequential()\n",
    "\n",
    "# Add layers\n",
    "# Input layer(13 features) 64 hidden nodes\n",
    "house.add(Dense(64, input_dim=13, activation='relu'))\n",
    "# Hidden layer\n",
    "house.add(Dense(64, activation='relu'))\n",
    "# Output layer\n",
    "house.add(Dense(1, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                896       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 5,121\n",
      "Trainable params: 5,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile\n",
    "house.compile(loss='mse',\n",
    "              optimizer='adam',\n",
    "              metrics=['mae'])\n",
    "\n",
    "house.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 29us/sample - loss: 21.4563 - mean_absolute_error: 2.6050\n",
      "2.6049935817718506\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "history = house.fit(X_train, y_train, batch_size=64, epochs=5000, validation_split=0.1, verbose=0)\n",
    "house_score = house.evaluate(X_test, y_test)\n",
    "print(f'{house_score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.986639 ],\n",
       "       [18.595602 ],\n",
       "       [20.552471 ],\n",
       "       [36.047703 ],\n",
       "       [22.32461  ],\n",
       "       [20.101768 ],\n",
       "       [27.794952 ],\n",
       "       [21.691828 ],\n",
       "       [18.74782  ],\n",
       "       [19.233744 ],\n",
       "       [18.939932 ],\n",
       "       [17.094229 ],\n",
       "       [17.15544  ],\n",
       "       [46.72579  ],\n",
       "       [17.165932 ],\n",
       "       [21.25587  ],\n",
       "       [24.413996 ],\n",
       "       [20.719221 ],\n",
       "       [18.528639 ],\n",
       "       [18.975666 ],\n",
       "       [11.454278 ],\n",
       "       [ 5.784954 ],\n",
       "       [20.452143 ],\n",
       "       [15.627238 ],\n",
       "       [20.498972 ],\n",
       "       [19.884533 ],\n",
       "       [26.220224 ],\n",
       "       [24.856539 ],\n",
       "       [11.027265 ],\n",
       "       [20.740759 ],\n",
       "       [20.067465 ],\n",
       "       [13.852317 ],\n",
       "       [31.877731 ],\n",
       "       [23.531637 ],\n",
       "       [17.72143  ],\n",
       "       [ 8.259029 ],\n",
       "       [15.417329 ],\n",
       "       [17.929897 ],\n",
       "       [19.079561 ],\n",
       "       [25.351543 ],\n",
       "       [26.023813 ],\n",
       "       [24.811964 ],\n",
       "       [13.707349 ],\n",
       "       [43.727703 ],\n",
       "       [31.511736 ],\n",
       "       [31.132042 ],\n",
       "       [27.20643  ],\n",
       "       [19.316538 ],\n",
       "       [20.458101 ],\n",
       "       [21.727041 ],\n",
       "       [32.991936 ],\n",
       "       [21.435942 ],\n",
       "       [12.2899065],\n",
       "       [15.131833 ],\n",
       "       [37.64485  ],\n",
       "       [25.828524 ],\n",
       "       [11.669664 ],\n",
       "       [45.957233 ],\n",
       "       [32.535816 ],\n",
       "       [21.655676 ],\n",
       "       [23.01232  ],\n",
       "       [15.211656 ],\n",
       "       [15.473843 ],\n",
       "       [19.764904 ],\n",
       "       [22.405962 ],\n",
       "       [21.94812  ],\n",
       "       [13.225294 ],\n",
       "       [23.619719 ],\n",
       "       [13.357178 ],\n",
       "       [ 8.503696 ],\n",
       "       [19.215628 ],\n",
       "       [27.084402 ],\n",
       "       [18.95303  ],\n",
       "       [13.788106 ],\n",
       "       [24.485857 ],\n",
       "       [19.492308 ],\n",
       "       [20.190184 ],\n",
       "       [22.706038 ],\n",
       "       [37.228634 ],\n",
       "       [10.828242 ],\n",
       "       [21.481195 ],\n",
       "       [37.42861  ],\n",
       "       [17.518402 ],\n",
       "       [13.30256  ],\n",
       "       [18.70678  ],\n",
       "       [18.849707 ],\n",
       "       [16.103407 ],\n",
       "       [21.993027 ],\n",
       "       [20.897467 ],\n",
       "       [26.356352 ],\n",
       "       [19.269613 ],\n",
       "       [19.457083 ],\n",
       "       [24.05076  ],\n",
       "       [32.02251  ],\n",
       "       [37.0435   ],\n",
       "       [19.340052 ],\n",
       "       [35.625835 ],\n",
       "       [55.14677  ],\n",
       "       [24.89353  ],\n",
       "       [51.860554 ],\n",
       "       [27.187399 ],\n",
       "       [24.889395 ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict\n",
    "y_pred = house.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7422479543850158"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7308717352959342"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg_fit = reg.fit(X_train, y_train)\n",
    "\n",
    "reg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1678683318343817"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mean_absolute_error(y_test, y_pred_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SfcFnOONyuNm"
   },
   "source": [
    "## Use the Keras Library to build an image recognition network using the Fashion-MNIST dataset (also comes with keras)\n",
    "\n",
    "- Load and preprocess the image data similar to how we preprocessed the MNIST data in class.\n",
    "- Make sure to one-hot encode your category labels\n",
    "- Make sure to have your final layer have as many nodes as the number of classes that you want to predict.\n",
    "- Try different hyperparameters. What is the highest accuracy that you are able to achieve.\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Remember that neural networks fall prey to randomness so you may need to run your model multiple times (or use Cross Validation) in order to tell if a change to a hyperparameter is truly producing better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szi6-IpuzaH1"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zv_3xNMjzdLI"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Use Hyperparameter Tuning to make the accuracy of your models as high as possible. (error as low as possible)\n",
    "- Use Cross Validation techniques to get more consistent results with your model.\n",
    "- Use GridSearchCV to try different combinations of hyperparameters. \n",
    "- Start looking into other types of Keras layers for CNNs and RNNs maybe try and build a CNN model for fashion-MNIST to see how the results compare."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_433_Keras_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
